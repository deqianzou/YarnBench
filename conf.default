##this file is used to configure generator propertyes

hadoop.home =/opt/hadoop-2.7.1
spark.home  =/opt/spark-1.5.2-bin-hadoop2.6
hibench.home=/opt/HiBench


jobs=hibench

user=wei

##run time(s)
runtime=100

hadoop.url = http://localhost:8088
##Hadoop Mapreduce job configure, Hadoop generator will randminly pick up one job to run
##   hadoop.jobs                     =wordcount,sort
##   hadoop.jobs.ratios              =1,2
##   hadoop.jobs.wordcount.jars      = ./a.jar
##   hadoop.jobs.wordcount.inputs    = /intput1,/input2
##   hadoop.jobs.wordcount.output    = /output
##   hadoop.jobs.wordcount.parameters= p1,p2,p3
##   hadoop.jobs.wordcount.keyvalues = k1:v1,k2:v2,k3:v3


##spark sql job configure
##   configure the possible path to store query 
sparksql.jobs.path             = /opt/apache-hive-2.0.0-bin/hive-testbench/sample-queries-tpch/

##   the final path to run query will be ./hive-test/query1
sparksql.jobs                   = tpch_query1.sql,tpch_query3.sql,tpch_query4.sql,tpch_query5.sql,tpch_query6.sql,tpch_query7.sql,tpch_query8.sql,tpch_query9.sql,tpch_query10.sql,tpch_query11.sql,tpch_query12.sql,tpch_query13.sql,tpch_query14.sql,tpch_query15.sql,tpch_query16.sql,tpch_query17.sql,tpch_query18.sql,tpch_query19.sql,



#sparksql.jobs.ratios            = 1

sparksql.jobs.keyvalues         = --master:yarn, --jars:/opt/apache-hive-2.0.0-bin/lib/mysql-connector-5.1.18.jar,--database:tpch_flat_orc_10             

##for hibench job, the only property needed is jobs to list all wanted application
##We assume the input data has been generated by user

#hibench.jobs       = wordcount,sort
#hibench.jobs.types = mapreduce,mapreduce 
#hibench.jobs.ratios = 2,1 


##configure for generators
generators = PoissonGenerator

generator.OrderGenerator.jobs       =sparksql
generator.OrderGenerator.order      =true
generator.OrderGenerator.round      =3
generator.OrderGenerator.range      =18 
generator.OrderGenerator.jobs.ratio =1
generator.OrderGenerator.queue      =default
generator.OrderGenerator.parameters.interval = 20
#

generator.PoissonGenerator.jobs=sparksql
generator.PoissonGenerator.jobs.ratios=1
generator.PoissonGenerator.queue=default
generator.PoissonGenerator.parameters.interval=10

 
##  generator.CapacityGenerator.jobs      =hibench
##  generator.CapacityGenerator.jobs.ratio=1
##  generator.CapacityGenerator.queue     =default
##  generator.CapacityGenerator.parameters.usedCapacity = 50
##  generator.CaoacityGeneratir.parameters.usedCapacity.slice = 0.3:70,0.4,80 





