##this file is used to configure generator propertyes

hadoop.home =/home/admin/hadoop-2.7.1
spark.home  =/home/admin/spark-2.0.1-bin-hadoop2.7
hibench.home=/home/admin/tool/YarnBench/HiBench


jobs=hibench

user=admin

##run time(s)
runtime=50

hadoop.url = http://localhost:8088
##Hadoop Mapreduce job configure, Hadoop generator will randminly pick up one job to run
##   hadoop.jobs                     =wordcount,sort
##   hadoop.jobs.ratios              =1,2
##   hadoop.jobs.wordcount.jars      = ./a.jar
##   hadoop.jobs.wordcount.inputs    = /intput1,/input2
##   hadoop.jobs.wordcount.output    = /output
##   hadoop.jobs.wordcount.parameters= p1,p2,p3
##   hadoop.jobs.wordcount.keyvalues = k1:v1,k2:v2,k3:v3


generators = TraceGenerator1


spark.jobs                           =kmeans1,kmeans2,kmeans3,pagerank1,pagerank2,pagerank3

spark.jobs.pagerank1.keyvalues         = --properties-file:/home/admin/HiBench/report/pagerank/spark/conf/sparkbench/spark.conf, --class: org.apache.spark.examples.SparkPageRank, --master:yarn, --deploy-mode:cluster, --num-executors:2,--executor-cores:16, --executor-memory:64g,none:/home/admin/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar                     
spark.jobs.pagerank1.inputs            =hdfs://host6:9100/HiBench/Pagerank/Input1/edges
#spark.jobs.pagerank1.inputs            =hdfs://host6:9100/HiBench/Pagerank/Input1/edges

#numbers of iterations
spark.jobs.pagerank1.parameters        =3   

spark.jobs.pagerank2.keyvalues         = --properties-file:/home/admin/HiBench/report/pagerank/spark/conf/sparkbench/spark.conf, --class: org.apache.spark.examples.SparkPageRank, --master:yarn, --deploy-mode:cluster,--num-executors:2,--executor-cores:16, --executor-memory:64g,none:/home/admin/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar                     
spark.jobs.pagerank2.inputs            =hdfs://host6:9100/HiBench/Pagerank/Input2/edges
#numbers of iterations
spark.jobs.pagerank2.parameters        =3

spark.jobs.pagerank3.keyvalues         = --properties-file:/home/admin/HiBench/report/pagerank/spark/conf/sparkbench/spark.conf, --class: org.apache.spark.examples.SparkPageRank, --master:yarn, --deploy-mode:cluster,--num-executors:2,--executor-cores:16, --executor-memory:64g,none:/home/admin/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar                     
spark.jobs.pagerank3.inputs            =hdfs://host6:9100/HiBench/Pagerank/Input3/edges
#numbers of iterations
spark.jobs.pagerank3.parameters        =3


spark.jobs.kmeans1.keyvalues           =--properties-file:/home/admin/HiBench/report/kmeans/spark/conf/sparkbench/spark.conf, --class: com.intel.hibench.sparkbench.ml.DenseKMeans, --master:yarn, --deploy-mode:cluster, --num-executors:5, --executor-cores:16, --executor-memory:64g, none:/home/admin/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar, -k:10, --numIterations:5
spark.jobs.kmeans1.inputs              =hdfs://host6:9100/HiBench/Kmeans/Input1/samples
spark.jobs.kmeans1.output              =none

spark.jobs.kmeans2.keyvalues           =--properties-file:/home/admin/HiBench/report/kmeans/spark/conf/sparkbench/spark.conf, --class: com.intel.hibench.sparkbench.ml.DenseKMeans, --master:yarn, --deploy-mode:cluster, --num-executors:5, --executor-cores:16, --executor-memory:64g, none:/home/admin/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar, -k:10, --numIterations:5
spark.jobs.kmeans2.inputs              =hdfs://host6:9100/HiBench/Kmeans/Input2/samples
spark.jobs.kmeans2.output              =none

spark.jobs.kmeans3.keyvalues           =--properties-file:/home/admin/HiBench/report/kmeans/spark/conf/sparkbench/spark.conf, --class: com.intel.hibench.sparkbench.ml.DenseKMeans, --master:yarn, --deploy-mode:cluster, --num-executors:5, --executor-cores:16, --executor-memory:64g, none:/home/admin/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar, -k:10, --numIterations:5
spark.jobs.kmeans3.inputs              =hdfs://host6:9100/HiBench/Kmeans/Input3/samples
spark.jobs.kmeans3.output              =none


##spark sql job configure
##   configure the possible path to store query 
sparksql.jobs.path                   = /home/admin/apache-hive-2.0.0-bin/hive-testbench/sample-queries-tpch/

##   the final path to run query will be ./hive-test/query1
#sparksql.jobs                   = tpch_query1.sql,tpch_query3.sql,tpch_query4.sql,tpch_query5.sql,tpch_query6.sql,tpch_query7.sql,tpch_query8.sql,tpch_query9.sql,tpch_query10.sql,tpch_query11.sql,tpch_query12.sql,tpch_query13.sql,tpch_query14.sql,tpch_query15.sql,tpch_query16.sql,tpch_query17.sql,tpch_query18.sql,tpch_query19.sql,


sparksql.jobs                        =tpch_query1.sql,tpch_query3.sql
#sparksql.jobs.ratios                = 1

sparksql.jobs.keyvalues              = --master:yarn, --jars:/home/admin/spark-1.6.1-bin-hadoop2.6/lib/mysql-connector-5.1.39-bin.jar,--database:tpch_flat_orc_10             

generator.TraceGenerator1.jobs=spark
generator.TraceGenerator1.queue=default
generator.TraceGenerator1.sync=1
generator.TraceGenerator1.ftrace=./trace/jmf

